{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study: Natural Language Processing with Deep Learning\n",
    "# Dataset: Dead By Daylight Steam Reviews\n",
    "# Author: Willian Oliveira and Julierme Silva\n",
    "# Start: 10/04/2023\n",
    "# Study Motivation: Train a machine to classify products based on user reviews\n",
    "# Notebook Motivation: The purpose of this notebook is to train a Support Vector Machine model to classify the reviews using Bag of Words.\n",
    "# Study Status: In Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries and setting up the environment\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    make_scorer,\n",
    ")\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "set_seeds()  # Setting seed for reproducible code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "X_train = np.load(\"data\\processed\\dbd_proc_train.npz\", allow_pickle=True)[\"X_train\"]\n",
    "y_train = np.load(\"data\\processed\\dbd_proc_train.npz\", allow_pickle=True)[\"y_train\"]\n",
    "X_val = np.load(\"data\\processed\\dbd_proc_val.npz\", allow_pickle=True)[\"X_val\"]\n",
    "y_val = np.load(\"data\\processed\\dbd_proc_val.npz\", allow_pickle=True)[\"y_val\"]\n",
    "X_test = np.load(\"data\\processed\\dbd_proc_test.npz\", allow_pickle=True)[\"X_test\"]\n",
    "y_test = np.load(\"data\\processed\\dbd_proc_test.npz\", allow_pickle=True)[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (138588,) y_train shape:  (138588,)\n",
      "X_val shape:  (17324,) y_val shape:  (17324,)\n",
      "X_test shape:  (17324,) y_test shape:  (17324,)\n"
     ]
    }
   ],
   "source": [
    "# Verifying the shape of the dataset\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape, \"y_train shape: \", y_train.shape)\n",
    "print(\"X_val shape: \", X_val.shape, \"y_val shape: \", y_val.shape)\n",
    "print(\"X_test shape: \", X_test.shape, \"y_test shape: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and validation sets since we are using Cross Validation\n",
    "\n",
    "X_train = np.concatenate((X_train, X_val))\n",
    "y_train = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  played many game life none left feeling horrible large chunk playerbase play torment others way transcending game anything match sole purpose making miserable throw insult mock match abide rule play nice likely loose flame anyway survivor killer player stuck gameplay loop inherently unfun side higher level play optimal also boring frustrating everyone many perk greatly unbalanced dominating game killer feel absolutely powerless helpless survivor dance front mock survivor get targetted frustrated killer tunneled game early vicious cycle hatred u v mentality frustration many people call toxic wear badge honour acting accordingly devs history acknowledging state community leaving feature exploit game specifically bully player nothing actual gameplay even told people issue play another game one past stream therefore unlikely ever get better issue extends accessibility issue macroes people use purely annoy others cause rapidly flashing light persisting drilling sound may cause severe headache even seizure photosensitive people poor understanding high level play devs result highly questionable balance combined aforementioned overwhelming toxicity caused game hemorrhage player last year another issue game year overwhelming amount hacker getting hack easy many people use many hack subtle enough know sure hacking lucky good especially since always see caught redhanded gaslight tell problem instead hack range simple thing like faster movement repair speed automated perfect dodge wild thing like teleports instant repair totem cleanse freezing killer action cancel preventing match ever end even timer forcing disconnect remove point challenge progress applies timed matchmaking ban also shown capable digging ip address game streamer even swatted due issue addressed devs continue exist untouched core gameplay addicting way keep bringing back horrible experience leave game come back forgetting bad defended game year even recommended friend cause fun thing character incredibly well designed art department general phenomenal also many horror icon cool experience game core gameplay fun reach high level play many killer unique gameplay style lore expanded time rich well written real treat care however toxicity gameplay getting worse worse year point state fundamentally rotten even associated content creator game struggle fun playing especially killer main sum game really entertaining early fall end horrible time get involved game hard stop playing good always come back bad time going downhill term balance community health even security issue properly addressed proper step taken recommend game anyone sadly long going see addressed neither near far future\n",
      "Label:   False \n",
      "\n",
      "Review:  killer perk vary nothing extremely overpowered chance winning killer unless shell money get best perk\n",
      "Label:   False \n",
      "\n",
      "Review:  great coop game good game loop\n",
      "Label:   True \n",
      "\n",
      "Review:  eu tento gostar desse jogo por sou desincentivado pelo jogo comunidade bug pela empresa e suas escolhas basicamente tudo que gira em torno desse jogo foda behaviour ma acho que eu deveria ter jogado melhor\n",
      "Label:   True \n",
      "\n",
      "Review:  trash game would play\n",
      "Label:   True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verifying the first 5 reviews and their labels\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Review: \", X_train[i])\n",
    "    print(\"Label:  \", y_train[i], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the dataset with Random Over Sampling\n",
    "\n",
    "rus = RandomUnderSampler(random_state=SEED)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train.reshape(-1, 1), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled shape:  (59248, 1) y_train_resampled shape:  (59248,)\n",
      "Positive reviews:  29624\n",
      "Negative reviews:  29624\n"
     ]
    }
   ],
   "source": [
    "# verify the shape of the resampled train dataset\n",
    "\n",
    "print(\"X_train_resampled shape: \", X_train_resampled.shape, \"y_train_resampled shape: \", y_train_resampled.shape)\n",
    "\n",
    "# verify proportion of positive and negative reviews\n",
    "\n",
    "print(\"Positive reviews: \", np.sum(y_train_resampled == 1))\n",
    "print(\"Negative reviews: \", np.sum(y_train_resampled == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X_train_resampled back to a 1D array to be used in the CountVectorizer\n",
    "\n",
    "X_train_resampled = X_train_resampled.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]\n",
      "Cross Validation Results:\n",
      "test_accuracy: 0.65 (+/- 0.02)\n",
      "test_precision: 0.65 (+/- 0.02)\n",
      "test_recall: 0.67 (+/- 0.02)\n",
      "test_f1: 0.66 (+/- 0.02)\n",
      "test_roc_auc: 0.65 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM model with Bag of Words in a Pipeline\n",
    "\n",
    "scoring_metrics = {\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"precision\": make_scorer(precision_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"roc_auc\": make_scorer(roc_auc_score),\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", CountVectorizer()),\n",
    "        (\"classifier\", SVC(kernel=\"sigmoid\", # Sigmoid kernel is used due to faster convergence and better performance on tuning tests\n",
    "                           random_state=SEED,\n",
    "                           verbose=True,\n",
    "                           tol=1e-3,\n",
    "                           max_iter=-1,\n",
    "                           probability=True)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "cv_results = cross_validate(pipeline,\n",
    "                            X_train_resampled, \n",
    "                            y_train_resampled, \n",
    "                            cv=5, \n",
    "                            scoring=scoring_metrics)\n",
    "\n",
    "print(\"\\nCross Validation Results:\")\n",
    "for metric, scores in cv_results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric}: {scores.mean():.2f} (+/- {scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]\n",
      "Holdout Set Results:\n",
      "Accuracy: 0.66\n",
      "Precision: 0.88\n",
      "Recall: 0.68\n",
      "F1: 0.77\n",
      "ROC AUC: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Using the holdout set to evaluate the final model\n",
    "\n",
    "pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\nHoldout Set Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_pred):.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/dbd_reviews_svm_bow.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model\n",
    "\n",
    "dump(pipeline, \"models/dbd_reviews_svm_bow.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
